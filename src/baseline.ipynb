{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-26T13:07:49.501329Z",
     "start_time": "2024-11-26T13:07:49.387409Z"
    }
   },
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "\n",
    "import yaml \n",
    "\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import lightning as L\n",
    "from pytorch_lightning.loggers import WandbLogger"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T12:34:25.489615Z",
     "start_time": "2024-11-26T12:34:25.189431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test\n",
    "backbone_weights = torchvision.models.ResNet34_Weights.DEFAULT\n",
    "preprocessor = backbone_weights.transforms()\n",
    "backbone = torchvision.models.resnet34(weights=backbone_weights)"
   ],
   "id": "ece694fe06b80972",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:38:22.278280Z",
     "start_time": "2024-11-26T13:38:22.274756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set parameters and write to yaml file\n",
    "parameters = {\n",
    "    'Training': {\n",
    "        'limit_train_batches': 1.0,\n",
    "        'max_epochs': 10,\n",
    "        'batch_size': 32,\n",
    " \n",
    "    },\n",
    "    'Optimizer': {\n",
    "        'optimizer': 'adam',\n",
    "        'weight_decay': 0.9,\n",
    "        'lr': 6e-6,  \n",
    "    },\n",
    "    'Loss_Function': {\n",
    "        'loss_function': 'qwk',\n",
    "    },\n",
    "    'Model': {\n",
    "        'backbone': 'resnet34',\n",
    "        'features': 512,\n",
    "        'outputs': 3,\n",
    "   },\n",
    "}\n",
    "\n",
    "parameters"
   ],
   "id": "7411a91035f8fbf8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Training': {'limit_train_batches': 1.0, 'max_epochs': 10, 'batch_size': 32},\n",
       " 'Optimizer': {'optimizer': 'adam', 'weight_decay': 0.9, 'lr': 6e-06},\n",
       " 'Loss_Function': {'loss_function': 'qwk'},\n",
       " 'Model': {'backbone': 'resnet34', 'features': 512, 'outputs': 3}}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:38:24.718793Z",
     "start_time": "2024-11-26T13:38:24.715699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"parameters.yaml\", 'w') as yaml_file:\n",
    "    data = yaml.dump(parameters, yaml_file)"
   ],
   "id": "8e63338b73b23c7d",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:38:24.912946Z",
     "start_time": "2024-11-26T13:38:24.908364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"parameters.yaml\", \"r\") as yaml_file:\n",
    "    parameters = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "print(parameters)"
   ],
   "id": "5e3703dc867ad4cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Loss_Function': {'loss_function': 'qwk'}, 'Model': {'backbone': 'resnet34', 'features': 512, 'outputs': 3}, 'Optimizer': {'lr': 6e-06, 'optimizer': 'adam', 'weight_decay': 0.9}, 'Training': {'batch_size': 32, 'limit_train_batches': 1.0, 'max_epochs': 10}}\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:38:42.327455Z",
     "start_time": "2024-11-26T13:38:42.322065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# fully-supervised fine-tuning\n",
    "class Backbone(L.LightningModule):\n",
    "    \n",
    "    def __init__(self, n_classes, user_parameters):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        self.user_parameters = user_parameters\n",
    "        \n",
    "        self.backbone_weights = torchvision.models.ResNet34_Weights.DEFAULT\n",
    "        self.preprocessor = self.backbone_weights.transforms()\n",
    "        self.backbone = torchvision.models.resnet34(weights=self.backbone_weights)\n",
    "        self.n_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Linear(self.n_features, self.n_classes)\n",
    "        \n",
    "        match self.user_parameters['Loss_Function']['loss_function']:\n",
    "            case 'cross_entropy':\n",
    "                self.loss_function = F.cross_entropy\n",
    "            case 'qwk':\n",
    "                from WeightedKappaLoss import WeightedKappaLoss\n",
    "                self.loss_function = WeightedKappaLoss(self.n_classes, mode='quadratic')\n",
    "            case _:\n",
    "                self.loss_function = F.cross_entropy  # defaults to cross entropy\n",
    "\n",
    "        self.save_hyperparameters()  # wandb\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_processed = self.preprocessor(x)\n",
    "        return self.backbone(x_processed)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.backbone.parameters(),\n",
    "            lr=self.user_parameters['Optimizer']['lr'],\n",
    "            weight_decay=self.user_parameters['Optimizer']['weight_decay'],\n",
    "        )\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        x_hat = self.forward(x)\n",
    "        loss = F.cross_entropy(x_hat, y)\n",
    "        self.log(\"train_loss\", loss)  # wandb\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        x_hat = self.forward(x)\n",
    "        loss = F.cross_entropy(x_hat, y)\n",
    "    \n",
    "    \n",
    "        "
   ],
   "id": "5bb9fe1b01bae0e1",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:38:43.061817Z",
     "start_time": "2024-11-26T13:38:43.059183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wandb_logger = WandbLogger(\n",
    "    project='debug-runs',\n",
    "    save_dir='wandb-outputs',\n",
    "    config=parameters,\n",
    ")"
   ],
   "id": "634b231e358d71a9",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:38:43.884692Z",
     "start_time": "2024-11-26T13:38:43.881137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fake_train_data = torchvision.datasets.FakeData(\n",
    "    size=1000,\n",
    "    image_size=(3, 512, 512),\n",
    "    num_classes=3,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "fake_val_data = torchvision.datasets.FakeData(\n",
    "    size=1000,\n",
    "    image_size=(3, 512, 512),\n",
    "    num_classes=3,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "fake_train_data"
   ],
   "id": "945419bcf58bb6ef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FakeData\n",
       "    Number of datapoints: 1000\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:38:45.286120Z",
     "start_time": "2024-11-26T13:38:45.283410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fake_train_dataloader = torch.utils.data.DataLoader(\n",
    "    batch_size=parameters['Training']['batch_size'],\n",
    "    dataset=fake_train_data,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "fake_val_dataloader = torch.utils.data.DataLoader(\n",
    "    batch_size=parameters['Training']['batch_size'],\n",
    "    dataset=fake_val_data,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")"
   ],
   "id": "c56654edc59e3ea5",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:38:46.154368Z",
     "start_time": "2024-11-26T13:38:45.856901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Backbone(n_classes=3, user_parameters=parameters)\n",
    "trainer = L.Trainer(\n",
    "    limit_train_batches=parameters['Training']['limit_train_batches'], \n",
    "    max_epochs=parameters['Training']['max_epochs'],\n",
    "    logger=wandb_logger,\n",
    ")"
   ],
   "id": "e407530417b98dd3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/Projects/multiple-instance-learning/src/WeightedKappaLoss.py:8: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  \"\"\"\n",
      "/home/felipe/Projects/multiple-instance-learning/src/WeightedKappaLoss.py:27: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  \"\"\"Creates a `WeightedKappaLoss` instance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:38:52.345601Z",
     "start_time": "2024-11-26T13:38:51.417798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for batch in fake_train_dataloader:\n",
    "    x, y = batch[0], batch[1]\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ],
   "id": "96ec8fc8b100b65d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 512, 512]) torch.Size([32])\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:38:53.619043Z",
     "start_time": "2024-11-26T13:38:53.271301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer.fit(model, fake_train_dataloader, fake_val_dataloader)\n",
    "wandb.finish()"
   ],
   "id": "4ee93e3fa9e5a13a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error in wandb.init()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/felipe/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py\", line 1255, in init\n",
      "    wi.setup(kwargs)\n",
      "  File \"/home/felipe/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py\", line 320, in setup\n",
      "    settings._apply_init(kwargs)\n",
      "  File \"/home/felipe/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_settings.py\", line 1918, in _apply_init\n",
      "    self.update(init_settings, source=Source.INIT)\n",
      "  File \"/home/felipe/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_settings.py\", line 1548, in update\n",
      "    self.__dict__[key].update(settings.pop(key), source=source)\n",
      "  File \"/home/felipe/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_settings.py\", line 615, in update\n",
      "    self._value = self._validate(self._preprocess(value))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felipe/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_settings.py\", line 585, in _validate\n",
      "    if not v(value):\n",
      "           ^^^^^^^^\n",
      "  File \"/home/felipe/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_settings.py\", line 1045, in _validate_project\n",
      "    raise UsageError(\n",
      "wandb.errors.errors.UsageError: Invalid project name 'debug-runs/multiple-instance-learning': cannot contain characters '/,\\\\,#,?,%,:', found '/'\n"
     ]
    },
    {
     "ename": "UsageError",
     "evalue": "Invalid project name 'debug-runs/multiple-instance-learning': cannot contain characters '/,\\\\,#,?,%,:', found '/'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUsageError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[105], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfake_train_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfake_val_dataloader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m wandb\u001B[38;5;241m.\u001B[39mfinish()\n",
      "File \u001B[0;32m~/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:538\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    536\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[1;32m    537\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 538\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    539\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[1;32m    540\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:47\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     46\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 47\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[1;32m     50\u001B[0m     _call_teardown_hook(trainer)\n",
      "File \u001B[0;32m~/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:574\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    567\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    568\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[1;32m    569\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[1;32m    570\u001B[0m     ckpt_path,\n\u001B[1;32m    571\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    572\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    573\u001B[0m )\n\u001B[0;32m--> 574\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    576\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[1;32m    577\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:943\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m    940\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: preparing data\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    941\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_connector\u001B[38;5;241m.\u001B[39mprepare_data()\n\u001B[0;32m--> 943\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_setup_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# allow user to set up LightningModule in accelerator environment\u001B[39;00m\n\u001B[1;32m    944\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: configuring model\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    945\u001B[0m call\u001B[38;5;241m.\u001B[39m_call_configure_model(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[0;32m~/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:96\u001B[0m, in \u001B[0;36m_call_setup_hook\u001B[0;34m(trainer)\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;66;03m# Trigger lazy creation of experiment in loggers so loggers have their metadata available\u001B[39;00m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m logger \u001B[38;5;129;01min\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mloggers:\n\u001B[0;32m---> 96\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mhasattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mlogger\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mexperiment\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m:\n\u001B[1;32m     97\u001B[0m         _ \u001B[38;5;241m=\u001B[39m logger\u001B[38;5;241m.\u001B[39mexperiment\n\u001B[1;32m     99\u001B[0m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mbarrier(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpre_setup\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/lightning_fabric/loggers/logger.py:118\u001B[0m, in \u001B[0;36mrank_zero_experiment.<locals>.experiment\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m rank_zero_only\u001B[38;5;241m.\u001B[39mrank \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _DummyExperiment()\n\u001B[0;32m--> 118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:406\u001B[0m, in \u001B[0;36mWandbLogger.experiment\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    403\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_experiment \u001B[38;5;241m=\u001B[39m wandb\u001B[38;5;241m.\u001B[39m_attach(attach_id)\n\u001B[1;32m    404\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    405\u001B[0m     \u001B[38;5;66;03m# create new wandb process\u001B[39;00m\n\u001B[0;32m--> 406\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_experiment \u001B[38;5;241m=\u001B[39m \u001B[43mwandb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wandb_init\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    408\u001B[0m     \u001B[38;5;66;03m# define default x-axis\u001B[39;00m\n\u001B[1;32m    409\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_experiment, (Run, RunDisabled)) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\n\u001B[1;32m    410\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_experiment, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdefine_metric\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    411\u001B[0m     ):\n",
      "File \u001B[0;32m~/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:1270\u001B[0m, in \u001B[0;36minit\u001B[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, resume_from, settings)\u001B[0m\n\u001B[1;32m   1266\u001B[0m     logger\u001B[38;5;241m.\u001B[39mexception(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124merror in wandb.init()\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39me)\n\u001B[1;32m   1268\u001B[0m \u001B[38;5;66;03m# Need to build delay into this sentry capture because our exit hooks\u001B[39;00m\n\u001B[1;32m   1269\u001B[0m \u001B[38;5;66;03m# mess with sentry's ability to send out errors before the program ends.\u001B[39;00m\n\u001B[0;32m-> 1270\u001B[0m \u001B[43mwandb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sentry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1271\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m()\n",
      "File \u001B[0;32m~/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/wandb/analytics/sentry.py:161\u001B[0m, in \u001B[0;36mSentry.reraise\u001B[0;34m(self, exc)\u001B[0m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexception(exc)\n\u001B[1;32m    159\u001B[0m \u001B[38;5;66;03m# this will messily add this \"reraise\" function to the stack trace,\u001B[39;00m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;66;03m# but hopefully it's not too bad\u001B[39;00m\n\u001B[0;32m--> 161\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\u001B[38;5;241m.\u001B[39mwith_traceback(sys\u001B[38;5;241m.\u001B[39mexc_info()[\u001B[38;5;241m2\u001B[39m])\n",
      "File \u001B[0;32m~/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:1255\u001B[0m, in \u001B[0;36minit\u001B[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, resume_from, settings)\u001B[0m\n\u001B[1;32m   1253\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1254\u001B[0m     wi \u001B[38;5;241m=\u001B[39m _WandbInit()\n\u001B[0;32m-> 1255\u001B[0m     \u001B[43mwi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1256\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m wi\u001B[38;5;241m.\u001B[39minit()\n\u001B[1;32m   1258\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:320\u001B[0m, in \u001B[0;36m_WandbInit.setup\u001B[0;34m(self, kwargs)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;66;03m# get status of code saving before applying user settings\u001B[39;00m\n\u001B[1;32m    318\u001B[0m save_code_pre_user_settings \u001B[38;5;241m=\u001B[39m settings\u001B[38;5;241m.\u001B[39msave_code\n\u001B[0;32m--> 320\u001B[0m \u001B[43msettings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m settings\u001B[38;5;241m.\u001B[39m_offline \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m settings\u001B[38;5;241m.\u001B[39m_noop:\n\u001B[1;32m    322\u001B[0m     user_settings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wl\u001B[38;5;241m.\u001B[39m_load_user_settings()\n",
      "File \u001B[0;32m~/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_settings.py:1918\u001B[0m, in \u001B[0;36mSettings._apply_init\u001B[0;34m(self, init_settings)\u001B[0m\n\u001B[1;32m   1915\u001B[0m         init_settings[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresume\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1917\u001B[0m \u001B[38;5;66;03m# update settings\u001B[39;00m\n\u001B[0;32m-> 1918\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43minit_settings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msource\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mSource\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mINIT\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1919\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_fork_logic()\n\u001B[1;32m   1920\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_rewind_logic()\n",
      "File \u001B[0;32m~/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_settings.py:1548\u001B[0m, in \u001B[0;36mSettings.update\u001B[0;34m(self, settings, source, **kwargs)\u001B[0m\n\u001B[1;32m   1546\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__modification_order:\n\u001B[1;32m   1547\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m settings:\n\u001B[0;32m-> 1548\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__dict__\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msettings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msource\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1550\u001B[0m \u001B[38;5;66;03m# update the remaining properties\u001B[39;00m\n\u001B[1;32m   1551\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m settings\u001B[38;5;241m.\u001B[39mitems():\n",
      "File \u001B[0;32m~/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_settings.py:615\u001B[0m, in \u001B[0;36mProperty.update\u001B[0;34m(self, value, source)\u001B[0m\n\u001B[1;32m    597\u001B[0m \u001B[38;5;66;03m# - always update value if source == Source.OVERRIDE\u001B[39;00m\n\u001B[1;32m    598\u001B[0m \u001B[38;5;66;03m# - if not previously overridden:\u001B[39;00m\n\u001B[1;32m    599\u001B[0m \u001B[38;5;66;03m#   - update value if source is lower than or equal to current source and property is policy\u001B[39;00m\n\u001B[1;32m    600\u001B[0m \u001B[38;5;66;03m#   - update value if source is higher than or equal to current source and property is not policy\u001B[39;00m\n\u001B[1;32m    601\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    602\u001B[0m     (source \u001B[38;5;241m==\u001B[39m Source\u001B[38;5;241m.\u001B[39mOVERRIDE)\n\u001B[1;32m    603\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    613\u001B[0m ):\n\u001B[1;32m    614\u001B[0m     \u001B[38;5;66;03m# self.__dict__[\"_value\"] = self._validate(self._preprocess(value))\u001B[39;00m\n\u001B[0;32m--> 615\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_preprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    616\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_source \u001B[38;5;241m=\u001B[39m source\n",
      "File \u001B[0;32m~/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_settings.py:585\u001B[0m, in \u001B[0;36mProperty._validate\u001B[0;34m(self, value)\u001B[0m\n\u001B[1;32m    581\u001B[0m     _validator \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    582\u001B[0m         [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validator] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validator) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validator\n\u001B[1;32m    583\u001B[0m     )\n\u001B[1;32m    584\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m _validator:\n\u001B[0;32m--> 585\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    586\u001B[0m             \u001B[38;5;66;03m# failed validation will likely cause a downstream error\u001B[39;00m\n\u001B[1;32m    587\u001B[0m             \u001B[38;5;66;03m# when trying to convert to protobuf, so we raise a hard error\u001B[39;00m\n\u001B[1;32m    588\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m SettingsValidationError(\n\u001B[1;32m    589\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid value for property \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    590\u001B[0m             )\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m value\n",
      "File \u001B[0;32m~/Projects/multiple-instance-learning/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_settings.py:1045\u001B[0m, in \u001B[0;36mSettings._validate_project\u001B[0;34m(value)\u001B[0m\n\u001B[1;32m   1043\u001B[0m     invalid_chars \u001B[38;5;241m=\u001B[39m {char \u001B[38;5;28;01mfor\u001B[39;00m char \u001B[38;5;129;01min\u001B[39;00m invalid_chars_list \u001B[38;5;28;01mif\u001B[39;00m char \u001B[38;5;129;01min\u001B[39;00m value}\n\u001B[1;32m   1044\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m invalid_chars:\n\u001B[0;32m-> 1045\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m UsageError(\n\u001B[1;32m   1046\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid project name \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1047\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot contain characters \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(invalid_chars_list)\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1048\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(invalid_chars)\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1049\u001B[0m         )\n\u001B[1;32m   1050\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mUsageError\u001B[0m: Invalid project name 'debug-runs/multiple-instance-learning': cannot contain characters '/,\\\\,#,?,%,:', found '/'"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:28:53.510542Z",
     "start_time": "2024-11-26T13:28:53.506432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for batch in fake_train_dataloader:\n",
    "    x, y = batch[0], batch[1]\n",
    "    y_hat = model(x)\n",
    "    acc = torch.metrics.accuracy(y_hat, y)\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ],
   "id": "4a193550567a979e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Backbone(\n",
       "  (preprocessor): ImageClassification(\n",
       "      crop_size=[224]\n",
       "      resize_size=[256]\n",
       "      mean=[0.485, 0.456, 0.406]\n",
       "      std=[0.229, 0.224, 0.225]\n",
       "      interpolation=InterpolationMode.BILINEAR\n",
       "  )\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c6935e04a34c895c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
